{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a563f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe 'undefined.-xfrozen_modules=off' kernel is not available. Please pick another suitable kernel instead, or install that kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/bike_buyers.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"ID\", axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=\"object\")\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_var = pd.DataFrame(df[col].value_counts())\n",
    "    df_var.columns = [\"freq_abs\"]\n",
    "\n",
    "    df_var[\"freq_rel\"] = df_var[\"freq_abs\"]/len(df)\n",
    "    df_var[\"freq_rel_%\"] = df_var[\"freq_rel\"]*100\n",
    "\n",
    "    display(df_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb050bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['int64', 'float64']).drop(\"ID\", axis=1).columns.tolist()\n",
    "\n",
    "n = len(num_cols)\n",
    "ncols = 2\n",
    "nrows = (n + ncols - 1) // ncols\n",
    "\n",
    "fig, axes = plt.subplots(ncols=ncols,nrows=nrows,figsize=(4*ncols, 4*nrows))\n",
    "\n",
    "axes = axes.flatten() if isinstance(axes, (list, np.ndarray)) else [axes]\n",
    "\n",
    "for ax, col in zip(axes, num_cols):\n",
    "    df[col].plot(kind='box', ax=ax)\n",
    "    ax.set_title(f\"Distribución de la variable {col}\")\n",
    "\n",
    "\n",
    "# hide any unused axes\n",
    "for ax in axes[len(num_cols):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_var = \"Purchased Bike\"\n",
    "cat_cols = df.select_dtypes(include=['object']).drop(target_var, axis=1).columns.tolist()\n",
    "# create a subplot grid that fits all categorical columns\n",
    "n = len(cat_cols)\n",
    "ncols = 2\n",
    "nrows = (n + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(5 * ncols, 4 * nrows))\n",
    "\n",
    "# ensure axes is a flat array for easy indexing\n",
    "axes = axes.flatten() if isinstance(axes, (list, np.ndarray)) else [axes]\n",
    "\n",
    "for ax, col in zip(axes, cat_cols):\n",
    "    crosstab_data = pd.crosstab(df[col], df[target_var])\n",
    "    crosstab_data.plot(kind='bar', stacked=True, ax=ax)\n",
    "    ax.set_title(f'Distribucion de {col} según {target_var}')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Cantidad')\n",
    "    ax.legend(title=target_var)\n",
    "\n",
    "# hide any unused axes\n",
    "for ax in axes[len(cat_cols):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la cantidad de valores na\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ea9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Imputaremos valores usando SimpleImputer\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# Separamos los tipos de valores\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "# Implementamos el imputador\n",
    "df_clean[num_cols] = num_imputer.fit_transform(df_clean[num_cols])\n",
    "df_clean[cat_cols] = cat_imputer.fit_transform(df_clean[cat_cols])\n",
    "\n",
    "print(\"\\nValores faltantes luego de la imputación\")\n",
    "print(df_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0515985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar outliers usando el método IQR para cada columna numérica\n",
    "num_cols = df_clean.select_dtypes(include=['int64', 'float64']).drop(\"ID\", axis=1).columns.tolist()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ANÁLISIS DE OUTLIERS (Método IQR)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for col in num_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Definir límites\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identificar outliers\n",
    "    outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)][col]\n",
    "    \n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Columna: {col}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"Q1 (25%): {Q1}\")\n",
    "    print(f\"Q3 (75%): {Q3}\")\n",
    "    print(f\"IQR: {IQR}\")\n",
    "    print(f\"Límite inferior: {lower_bound}\")\n",
    "    print(f\"Límite superior: {upper_bound}\")\n",
    "    print(f\"Cantidad de outliers: {len(outliers)} ({len(outliers)/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar Winsorización usando método IQR (más efectivo)\n",
    "num_cols = df_clean.select_dtypes(include=['int64', 'float64']).drop([\"ID\", \"Cars\"], axis=1).columns.tolist()\n",
    "\n",
    "print(\"Tratamiento de outliers con Winsorización (método IQR):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in num_cols:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_before = ((df_clean[col] < lower) | (df_clean[col] > upper)).sum()\n",
    "    \n",
    "    df_clean[col] = np.clip(df_clean[col], lower, upper)\n",
    "    \n",
    "    outliers_after = ((df_clean[col] < lower) | (df_clean[col] > upper)).sum()\n",
    "    \n",
    "    print(f\"{col}:\")\n",
    "    print(f\"  Outliers antes: {outliers_before}\")\n",
    "    print(f\"  Outliers después: {outliers_after}\")\n",
    "    print(f\"  Límites: [{lower:.2f}, {upper:.2f}]\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798af73e",
   "metadata": {},
   "source": [
    "## Construccion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una columna para agrupar a los compradores por tiers de income\n",
    "bins = [0, 30000, 80000, np.inf]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "df['Income_Group'] = pd.cut(df['Income'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un ratio de dependencia: ninos por poseedores de autos\n",
    "df['Dependency_Ratio'] = df['Children'] / (df['Cars'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos grupos de edades (binning)\n",
    "bins_age = [0, 35, 55, np.inf]\n",
    "labels_age = ['Young Adult', 'Middle-Aged', 'Senior']\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=bins_age, labels=labels_age, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamos la distancia de viaje a un punto medio numerico\n",
    "commute_map = {\n",
    "    '0-1 Miles': 0.5,\n",
    "    '1-2 Miles': 1.5,\n",
    "    '2-5 Miles': 3.5,\n",
    "    '5-10 Miles': 7.5,\n",
    "    '10+ Miles': 12.0 \n",
    "}\n",
    "df['Commute_Midpoint_Miles'] = df['Commute Distance'].map(commute_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizamos la columna (0/1)\n",
    "df['Purchased Bike'] = df['Purchased Bike'].map({'Yes': 1, 'No': 0})\n",
    "df['Home Owner'] = df['Home Owner'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0577b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un mapeo de nivel de educacion a valores enteros\n",
    "# Esto facilita el entrenamiento posterior de los modelos.\n",
    "education_mapping = {\n",
    "    'Partial High School': 1,\n",
    "    'High School': 2,\n",
    "    'Partial College': 3,\n",
    "    'Bachelors': 4,\n",
    "    'Graduate': 5,\n",
    "    'Post-Graduate': 6 \n",
    "}\n",
    "\n",
    "# Creamos una nueva columna para mantener la antigua por ahora\n",
    "df['Education_Rank'] = df['Education'].map(education_mapping)\n",
    "\n",
    "# Confirmamos el cambio\n",
    "print(df[['Education', 'Education_Rank']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Nix)",
   "language": "python",
   "name": "nix-kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
